{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=[]\n",
    "y1=[]\n",
    "for ind,x in df.iterrows():\n",
    "    if(x[0]==1):\n",
    "        x1.append(x[1:])\n",
    "        y1.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "def SMOTE(X, y, N, k):\n",
    "\n",
    "    X_synthetic = []\n",
    "    y_synthetic = []\n",
    "\n",
    "    for i in range(N):\n",
    "        random_index = np.random.choice(len(X))\n",
    "        target_sample = X[random_index]\n",
    "\n",
    "        distances = np.array([euclidean_distance(target_sample, x) for x in X])\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        k_nearest_indices = sorted_indices[1:k+1]\n",
    "  \n",
    "        nn_index = np.random.choice(k)\n",
    "        nn_sample = X[k_nearest_indices[nn_index]]\n",
    "\n",
    "        rand = np.random.random()\n",
    "\n",
    "        synthetic_sample = target_sample + rand * (nn_sample - target_sample)\n",
    "        X_synthetic.append(synthetic_sample)\n",
    "        y_synthetic.append(y[random_index])\n",
    "\n",
    "    X_synthetic = np.array(X_synthetic)\n",
    "    y_synthetic = np.array(y_synthetic)\n",
    "\n",
    "    return X_synthetic, y_synthetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=SMOTE(x1,y1,4000,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4000):\n",
    "    temp=[1]\n",
    "    for j in range(0,len(x[i])):\n",
    "        temp.append(x[i][j])\n",
    "    df.loc[len(df.index)] =temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs=len(df)\n",
    "df=df.sample(frac=1)\n",
    "train_size=int(0.8*n_inputs)\n",
    "train_data=df[0:train_size]\n",
    "train_data=np.array(train_data.values)\n",
    "test_data=df[train_size:]\n",
    "test_data=np.array(test_data.values)\n",
    "y_train=train_data[:, 0]\n",
    "train_data=train_data[:, 1:]\n",
    "y_test=test_data[:, 0]\n",
    "test_data=test_data[:, 1:]\n",
    "n_features=train_data.shape[1]\n",
    "test_data_size=len(test_data)\n",
    "train_data_size=len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min-Max standardisation\n",
    "for i in range(0,n_features):\n",
    "    mi=1e10\n",
    "    ma=0\n",
    "    for j in range(0,train_data_size):\n",
    "        mi=min(mi,train_data[j][i])\n",
    "        ma=max(ma,train_data[j][i])\n",
    "    if(ma==mi):\n",
    "        continue\n",
    "    for j in range(0,train_data_size):\n",
    "        train_data[j][i]-=mi\n",
    "        train_data[j][i]/=(ma-mi)\n",
    "for i in range(0,n_features):\n",
    "    mi=1e10\n",
    "    ma=0\n",
    "    for j in range(0,test_data_size):\n",
    "        mi=min(mi,test_data[j][i])\n",
    "        ma=max(ma,test_data[j][i])\n",
    "    if(ma==mi):\n",
    "        continue\n",
    "    for j in range(0,test_data_size):\n",
    "        test_data[j][i]-=mi\n",
    "        test_data[j][i]/=(ma-mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if(x<0):\n",
    "        return np.exp(x)/(1+np.exp(x))\n",
    "    else:\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "    \n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "def relu_derivative(x, alpha=0.01):\n",
    "    return np.where(x > 0, 1, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers=4\n",
    "n_neurons=[n_features,5,5,1]\n",
    "activators=[\"None\",\"Relu\",\"Relu\",\"Sig\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising weights and bias for the layers\n",
    "weights=[0]\n",
    "bias=[0]\n",
    "for i in range(1,n_layers):\n",
    "    rows=n_neurons[i]\n",
    "    cols=n_neurons[i-1]\n",
    "    if(activators[i]==\"Relu\"):\n",
    "        #he initialization\n",
    "        w=np.random.randn(rows,cols)*np.sqrt(2.0/(cols+rows))\n",
    "        b=np.random.randn(rows,1)*np.sqrt(2.0/(cols+rows))\n",
    "        weights.append(w)\n",
    "        bias.append(b)\n",
    "    else:\n",
    "        # xavier initialization\n",
    "        w=np.random.randn(rows,cols)*np.sqrt(6.0/(cols+rows))*4.0\n",
    "        b=np.random.randn(rows,1)*np.sqrt(6.0/(cols+rows))*4.0\n",
    "        weights.append(w)\n",
    "        bias.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(x):\n",
    "    a=[x]       #holds activation value\n",
    "    z=[0]       #holds preactivation values\n",
    "    for i in range(1,n_layers):\n",
    "        if(activators[i]==\"Relu\"):\n",
    "            z.append(np.matmul(weights[i],a[i-1])+bias[i])\n",
    "            sz=z[i].shape[0]\n",
    "            temp=np.zeros((sz,1))\n",
    "            for j in range(0,sz):\n",
    "                temp[j][0]=relu(z[i][j][0])\n",
    "            a.append(temp)\n",
    "        else:\n",
    "            z.append(np.matmul(weights[i],a[i-1])+bias[i])\n",
    "            sz=z[i].shape[0]\n",
    "            temp=np.zeros((sz,1))\n",
    "            for j in range(0,sz):\n",
    "                temp[j][0]=sigmoid(z[i][j][0])\n",
    "            a.append(temp)\n",
    "    return a,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(x,y):\n",
    "    a,z=feedforward(x)\n",
    "    pred_value=a[n_layers-1]\n",
    "    t=(pred_value-y)*relu_derivative(z[n_layers-1])\n",
    "    deltas=[]\n",
    "    deltas.append(t)\n",
    "    i=n_layers-2\n",
    "    curr=0\n",
    "    while(i>0):\n",
    "        rows=z[i].shape[0]\n",
    "        cols=z[i].shape[1]\n",
    "        temp=np.zeros((rows,cols))\n",
    "        for j in range(0,rows):\n",
    "            for k in range(0,cols):\n",
    "                if(activators[i]==\"Relu\"):\n",
    "                 temp[j][k]=relu_derivative(z[i][j][k])   # temp stores the derivatives of the activation function for each neuron in that layer \n",
    "                else:\n",
    "                 temp[j][k]=sigmoid_derivative(z[i][j][k])\n",
    "        d=np.array(deltas[curr])\n",
    "        temp1=np.matmul(np.transpose(weights[i+1]),d)           # calculating error gradient for curr layer using error gradient of next layer\n",
    "        for j in range(0,rows):\n",
    "            for k in range(0,cols):\n",
    "                temp1[j][k]=temp1[j][k]*temp[j][k]           #   calculating delta and stroing it into temp1\n",
    "        \n",
    "        deltas.append(temp1)                                #deltas represent the gradient of the loss function with respect to the pre-activation values of the neurons in that layer\n",
    "        curr+=1\n",
    "        i-=1\n",
    "    deltas.append(0)\n",
    "    deltas.reverse()\n",
    "    for i in range(0,n_layers-1):\n",
    "        d=np.array(deltas[i+1])\n",
    "        grad=np.matmul(d,np.transpose(a[i]))\n",
    "        weights[i+1]=weights[i+1]-learning_rate*grad\n",
    "        bias[i+1]=bias[i+1]-learning_rate*d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0,10):\n",
    "    x=np.zeros((n_features,1))\n",
    "    for i in range(0,train_data_size):\n",
    "        for j in range(0,n_features):\n",
    "            x[j][0]=train_data[i][j]\n",
    "        backpropagate(x,y_train[i])\n",
    "    count0=0\n",
    "    count1=0\n",
    "    count_true0=0\n",
    "    count_true1=0\n",
    "    count=0\n",
    "    count_true=0\n",
    "    x=np.zeros((n_features,1))\n",
    "    for i in range(0,test_data_size):\n",
    "            for j in range(0,n_features):\n",
    "                x[j][0]=test_data[i][j]\n",
    "            a,z=feedforward(x)\n",
    "            if(a[n_layers-1]>=0.50):\n",
    "                prediction=1\n",
    "            else:\n",
    "                prediction=0\n",
    "            if(prediction==y_test[i]):\n",
    "                count_true+=1\n",
    "                if(prediction==1):\n",
    "                     count_true1+=1\n",
    "                else:\n",
    "                     count_true0+=1\n",
    "            if(y_test[i]==1):\n",
    "                 count1+=1\n",
    "            else:\n",
    "                 count0+=1\n",
    "            count+=1\n",
    "    print(count_true/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "count_true=0\n",
    "c=0\n",
    "x=np.zeros((n_features,1))\n",
    "for i in range(0,test_data_size):\n",
    "    for j in range(0,n_features):\n",
    "        x[j][0]=test_data[i][j]\n",
    "    a,z=feedforward(x)\n",
    "    if(a[n_layers-1]>=0.50):\n",
    "        prediction=1\n",
    "    else:\n",
    "         prediction=0\n",
    "    if(prediction==0):\n",
    "        c+=1\n",
    "    if(prediction==y_test[i] and y_test[i]==1):\n",
    "        count+=1\n",
    "    if(y_test[i]==1):\n",
    "        count_true+=1\n",
    "print(count/count_true)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "count_true=0\n",
    "c=0\n",
    "x=np.zeros((n_features,1))\n",
    "for i in range(0,train_data_size):\n",
    "    for j in range(0,n_features):\n",
    "        x[j][0]=train_data[i][j]\n",
    "    a,z=feedforward(x)\n",
    "    if(a[n_layers-1]>=0.50):\n",
    "        prediction=1\n",
    "    else:\n",
    "         prediction=0\n",
    "    if(prediction==0):\n",
    "        c+=1\n",
    "    if(prediction==y_train[i] and y_train[i]==1):\n",
    "        count+=1\n",
    "    if(y_train[i]==1):\n",
    "        count_true+=1\n",
    "precision_train=count/count_true\n",
    "print(f'Precision: {precision_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1=0\n",
    "count_true0=0\n",
    "count_true1=0\n",
    "count=0\n",
    "count_true=0\n",
    "x=np.zeros((n_features,1))\n",
    "for i in range(0,test_data_size):\n",
    "    for j in range(0,n_features):\n",
    "        x[j][0]=test_data[i][j]\n",
    "    a,z=feedforward(x)\n",
    "    if(a[n_layers-1]>=0.50):\n",
    "        prediction=1\n",
    "    else:\n",
    "        prediction=0\n",
    "    if(prediction==y_test[i]):\n",
    "        count_true+=1\n",
    "        if(prediction==1):\n",
    "            count_true1+=1\n",
    "        else:\n",
    "            count_true0+=1\n",
    "    count+=1\n",
    "acc = count_true/count\n",
    "print(f'Accuracy test: {acc}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1=0\n",
    "count_true0=0\n",
    "count_true1=0\n",
    "count=0\n",
    "count_true=0\n",
    "x=np.zeros((n_features,1))\n",
    "for i in range(0,train_data_size):\n",
    "    for j in range(0,n_features):\n",
    "        x[j][0]=train_data[i][j]\n",
    "    a,z=feedforward(x)\n",
    "    if(a[n_layers-1]>=0.50):\n",
    "        prediction=1\n",
    "    else:\n",
    "        prediction=0\n",
    "    if(prediction==y_train[i]):\n",
    "        count_true+=1\n",
    "        if(prediction==1):\n",
    "            count_true1+=1\n",
    "        else:\n",
    "            count_true0+=1\n",
    "    count+=1\n",
    "acc_train = count_true/count\n",
    "print(f'Accuracy training: {acc_train}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=0\n",
    "fn=0\n",
    "for i in range(0,test_data_size):\n",
    "    for j in range(0,n_features):\n",
    "                x[j][0]=test_data[i][j]\n",
    "    a,z=feedforward(x)\n",
    "    if(a[n_layers-1]>=0.50):\n",
    "        prediction=1\n",
    "    else:\n",
    "        prediction=0\n",
    "    if(prediction==1):\n",
    "        if(y_test[i]==1):\n",
    "                      tp+=1\n",
    "        else:\n",
    "                      fn+=1\n",
    "    if(prediction==0):\n",
    "                if(y_test[i]==1):\n",
    "                      fn+=1\n",
    "recall=tp/(tp+fn)\n",
    "print(f'Recall: {tp/(tp+fn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=0\n",
    "fn=0\n",
    "for i in range(0,train_data_size):\n",
    "    for j in range(0,n_features):\n",
    "                x[j][0]=train_data[i][j]\n",
    "    a,z=feedforward(x)\n",
    "    if(a[n_layers-1]>=0.50):\n",
    "        prediction=1\n",
    "    else:\n",
    "        prediction=0\n",
    "    if(prediction==1):\n",
    "        if(y_train[i]==1):\n",
    "                      tp+=1\n",
    "        else:\n",
    "                      fn+=1\n",
    "    if(prediction==0):\n",
    "                if(y_train[i]==1):\n",
    "                      fn+=1\n",
    "recall_train=tp/(tp+fn)\n",
    "print(f'Recall: {recall_train}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32dbabc90dd4d77dd2537a454396bdaa90f9684860be762d20438a91ed290ce7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
